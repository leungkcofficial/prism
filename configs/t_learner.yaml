# PRISM T-Learner Configuration
# Two separate models for A=0 and A=1

project:
  name: prism
  mode: t_learner
  model_type: deepsurv
  experiment_name: prism_t_learner

# Cohort formation parameters (same as S-learner)
cohort:
  egfr_screen_lt15_min_days: 90
  egfr_screen_lt15_max_days: 365
  t0_threshold: 10.0
  outpatient_only: true
  require_confirmatory_egfr: false
  early_window_days: 90
  study_end_date: "2023-12-31"
  max_followup_days: 1825

# Feature extraction parameters (same as S-learner)
features:
  lab_lookback_days: 90
  cci_lookback_years: 5
  derive_uacr_from_upcr: true
  lab_features:
    - creatinine
    - hemoglobin
    - albumin
    - a1c
    - phosphate
    - calcium
    - bicarbonate
    - uacr

# Data splitting parameters (same as S-learner)
splitting:
  temporal_test_start: "2022-01-01"
  spatial_test_frac: 0.10
  random_seed: 42

# Imputation parameters (same as S-learner)
imputation:
  method: mice
  max_iter: 10
  estimator: extratrees
  random_seed: 42
  hard_truth:
    - key
    - gender
    - A
    - duration
    - event
  med_history_pattern: "^(myocardial|congestive|peripheral|cerebrovascular|dementia|copd|rheumatic|peptic|liver|diabetes|hemiplegia|renal|cancer|metastatic|aids)"

# Preprocessing parameters (same as S-learner)
preprocessing:
  log_transform_features:
    - creatinine
    - phosphate
    - uacr
  log_transform_threshold: 1.0
  scaling_method: minmax
  scaling_range: [0, 1]
  binarize_cci: true

# Cross-validation parameters (same as S-learner)
cv:
  method: kfold
  n_folds: 10
  random_seed: 42

# Hyperparameter optimization (same as S-learner)
tuning:
  engine: optuna
  n_trials: 50
  timeout: 3600
  pruner: median
  learning_rate: [0.0001, 0.01]
  hidden_layers:
    - [128, 64]
    - [256, 128, 64]
    - [128, 64, 32]
    - [256, 128]
  dropout: [0.1, 0.5]
  batch_size: [128, 256, 512]
  weight_decay: [0.0, 0.001]

# Model training parameters (same as S-learner)
model:
  architecture: mlp
  hidden_layers: [128, 64, 32]
  dropout: 0.3
  batch_norm: true
  optimizer: adam
  learning_rate: 0.001
  weight_decay: 0.0
  epochs: 100
  batch_size: 256
  early_stopping:
    enabled: true
    patience: 10
    min_delta: 0.001
  loss: cox_ph
  device: cuda

# T-learner specific parameters
t_learner:
  enabled: true
  include_treatment_as_feature: false  # A NOT as feature (separate models)

  # Train two separate models
  train_separate_models: true

  # Model for A=0 (non-early dialysis)
  model_A0:
    hidden_layers: [128, 64, 32]
    dropout: 0.3

  # Model for A=1 (early dialysis)
  model_A1:
    hidden_layers: [128, 64, 32]
    dropout: 0.3

  # Check sample size requirements
  min_samples_per_group: 50  # Warn if either group has <50 patients

# Evaluation parameters (same as S-learner)
evaluation:
  time_points: [365, 1095, 1825]
  metrics:
    - cindex
    - brier
    - calibration
    - log_likelihood
  causal_metrics:
    - ate
    - att
  bootstrap:
    enabled: true
    n_bootstrap: 1000
    confidence_level: 0.95
    random_seed: 42
  generate_plots:
    - calibration_curves
    - survival_curves
    - risk_difference_distribution

# MLflow tracking
mlflow:
  tracking_uri: "mlruns"
  experiment_name: prism_t_learner
  log_models: true
  log_artifacts: true

# Output paths
output:
  model_dir: "models/t_learner"
  results_dir: "results/t_learner"
  plots_dir: "results/t_learner/plots"
  preprocessing_path: "models/t_learner/preprocessing_pipeline.pkl"
  model_A0_path: "models/t_learner/model_A0.pth"
  model_A1_path: "models/t_learner/model_A1.pth"
